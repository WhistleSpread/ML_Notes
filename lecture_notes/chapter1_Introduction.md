chapter1





### 4 模型类型

回忆一下，机器学习的目标就是要基于已有的数据进行估计或者泛化，下面我们就来看一下在机器学习中建模所扮演什么样的角色；

#### 4.1 没有模型

在一下简单的问题当中，我们可以直接从训练数据中产生预测结果，而不需要构建中间的模型；比如说在回归或者分类的问题中，我们对一个新的query可以产生一个答案，这个答案可以是平均一下最近的几个query得到的一个答案，比如说最近邻算法就是这个样子；

#### 4.2 预测规则

这两步过程非常的典型：

1. 找到一个能够很好的拟合训练数据的模型
2. 用这个模型来直接做决策

在前面所说的*预测规则*这种设定下，考虑回归或者是分类问题，这个模型就会是一些假设或者说是一个预测规则$y = h(x;\theta)$(这些假设或者预测规则往往是以某种函数$h$的形式呈现), 基本的想法就是$\theta$是一个向量，这个向量有1个或者多个参数值，这些参数值的确定是通过让模型不断的去拟合训练数据来确定出来的，然后我们再将这些参数确定下来。给定一个新的值$x^{n+1}$, 我们的预测结果就是$h(x^{n+1};\theta)$.

整个拟合的过程其实上就是一个最优化的问题：找到一组值$\theta$,从而能够最小化某些关于$\theta$和数据的某个条件；如果我们知道关于数据的实际潜在分布,那么$P_r(X, Y)$将预测y的值，使预期损失（这也称为测试误差）最小化。如果我们没有那个实际的基础分布，或者甚至没有它的估计，我们可以采取最小化训练误差的方法。也就是说，我们要找一个预测规则$h$,这个预测规则能够最小化在训练集上的平均损失，所以我们的目标就是找到这样的一组$\theta$,可以最小化:

$$\epsilon_{n}(\theta) = \frac 1 n \sum_{i=1}^n L(h(x^i;\theta), y^i)$$

损失函数$L(g, a)$ 衡量的是当实际值是a,可是我猜测是g, 这个猜测的糟糕程度；我们会发现，仅仅只是最小化训练误差通常不是一个好的选择；因为这样有可能会太过于强调拟合当前的数据结果当出现一个没有见过的新值$x$的时候就不能很好的泛化；

>这里为什么要谈论说可以得到数据的实际分布呢？得到的数据的实际分布那还要模型干嘛？这里不太明白；



### 5 模型类和参数拟合

一个模型类 $M$是一组可能的模型集合，这一类模型通常由参数Θ矢量参数化，那么我们对模型的形式作粗怎样的假设呢？当求解一个回归问题的时候，我们使用“预测规则方法”， 我们可能会尝试找到一个线性函数$h(x;\theta, \theta_0) = \theta^Tx + \theta_0$, 来很好的拟合数据，在这个例子中，参数向量$\Theta = (\theta, \theta_0)$.

对于像判别和分类这样一类的问题，人们研究了许许多多类的模型，我们会花大量的时间来探讨这些模型类，特别是神经网络模型，我们所讨论的模型类的参数都是固定的有限的参数，如果模型的参数不是固定的，或者参数的个数是无穷多个，那么这一类的模型我们称为“非参数”模型；

那么我们如何选择一个模型类呢？在某些情况下，机器学习实践者们会有自己的经验，他们知道什么样的模型类比较合适；在其他情况下，我们会同时考虑结果模型类，在这种情况下我们就是在求解一个模型选择问题；模型类的选择就是要确定使用哪一类的模型，模型拟合就是在确定了一个模型类之后在这个模型类中确定固定的参数；



### 6 算法

一旦我们已经描述了一类模型并且有了针对给定数据对一个模型进行打分的机制，那么接下来我们就面临着关于算法的问题: 我们应该设计一个什么样的算法从这个模型类问题中找到一个好的模型呢？比如说确定一组参数向量$\theta$，这组参数向量用来最小化$\epsilon_n(\theta)$, 我们可以使用我们所熟悉的最小二乘算法；最终模型$h$会收敛到拟合数据$x$;

有时候，我们可以用一些软件来进行最优化问题的求解；在许多其他情况下，我们使用专门用于机器学习问题或特定假设类的算法。

又一些算法不容易被轻易看作是是去优化特定的条件；实际上，我们所研究的第一个算法(找线性分类器)，感知机，都具有这种特点；