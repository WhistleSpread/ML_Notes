### 1. 分类

一个二分类的分类器就是将一个d维度的向量映射到集合$\{-1, +1\}$, 我们会经常用到字母$h$(for hypothesis) 来表示一个假设的分类器，分类的过程其实就是输入一个x,输出一个y;

在现实生活中很少给我们实数向量，我们在生活中想要分类的输入往往是比如说是一首歌，一张图片或者说是一个人；在这些实例中，我们需要定义一个函数$\phi(x)$, 输入是一个d维的向量，这个向量代表着输入x的特征，比如说像是一个人的身高，或者说是一首歌的低音，将特征向量输入到$\phi(x)$中，就可以得到输出为1或者是-1; 你必须要知道，在我们的实际应用机器学习算法的时候，一定有一个feature represantation 的过程；

在监督学习中，我们手上有一组训练数据集
$$
D_n = \{ (x^1, y^1), ..., (x^n, y^n)\}
$$
我们假设每一个$x^i$都是一个d维的列向量，也就是说，给了一个输入$x^i$, 那么 learned hypothesis 就会相应的有一个输入$y^i$;

我们说，一个分类器它之所以有用，是因为这个分类器可以作用于新的未知的数据，也就是说这个分类器对于它没有见过的样例也能够作出很好的预测；但是我们并不知道在真实的使用这个分类器的时候，这个分类器到底会遇到什么样的数据，因此我们不得不去假设在训练数据和测试数据之间存在着某种联系；通常情况下，训练数据和测试数据都是独立同分布与相同的概率分布的；

给定了一个训练集$D_n$, 以及一个分类器$h$, 我们可以定义$h$的训练误差为:
$$
\epsilon_n(h) = \frac 1 n \sum_{i=1}^n 
\begin{cases}
1 & h(x^i) \ne y^i \\
0 & otherwise
\end{cases}
$$
现在我们的目标是要找一个分类器，这个分类器的训练误差要尽可能的小(之后我们不会仅仅考虑训练误差，我们还会加入一下其他的限制，不过现在，我们暂时只考虑分类误差)，并且希望这个分类器能够很好的泛化预测新的数据，且希望这个分类器有小的测试误差(在测试集t上的表现误差)
$$
\epsilon_n(h) = \frac 1 {n^{t}} \sum_{i=n+1}^{n+n^t} 
\begin{cases}
1 & h(x^i) \ne y^i \\
0 & otherwise
\end{cases}
$$


这些$n^t$个新的例子都没有被用在寻找求解器的过程中；



### 2. 学习算法

在一个假设类(hypothesis class)$H$是一个集合(可以是有限的集合也可以是无限的集合)，在这个集合中的每一个分类器都代表着一个映射；一个学习算法的过程就是这样的一个过程：输入一个数据集$D_n$, 作为输入，返回的一个$h$，其实就是hypothesis class 中的某一个；我们之后就会看到，在假设类$(hypothesis class) H$ 中选择一个$h$对 *test error* 也就是在测试集上的误差会有非常大的影响，如果要让$h$，具有比较好的泛化能力的话，一种方法就是限制它的规模，不要让其size过大，或者说限制$H$的表达$“expressiveness” of H.$；



### 3. 线性分类器

我们接触到的第一个$hypothesis\   class$ 就是线性分类器, 线性分类器理解起来相对容易，数学含义简单，并且自身也比较强大，而且还是其他许多复杂方法的基础；

一个在d维度的线性分类器是由一组在d维的参数向量$\theta$, 以及一个标量$\theta_0$所定义的, 因此在d维上的线性分类器的假设空间$H$，就是在$R^{d+1}$空间上的一个d+1维的向量；我们先假设$\theta$是一个$n\times1$的列向量；

当给定了确定的$\theta$和$\theta_0$时，分类器就可以被定义成如下的样子：
$$
h(x;\theta, \theta_0) =sign(\theta^Tx+\theta_0) 
\begin{cases}
+1 & if \ \theta^Tx+\theta_0 > 0 \\
-1 & otherwise
\end{cases}
$$

>一定要小心维数这个问题，我们已经假设了$x$和$\theta$都是$n\times1$维的列向量，因此$\theta^Tx$就是$1\times1$，在数学上其实就是一个标量，(但是在用numpy编程的时候要小心)，你还要稍微自己处理一下；

要记住，我们可以把$\theta$, $\theta_0$可以看成是一个确定的超平面，这个超平面能够分开一个$\mathcal{R^d}$空间，一边是正的半空间，我们在这半边将所有的点分类为正，另一半空间是所有的负半空间，我们将所有的点分类为负数； 

>对于一个线性分类器$\theta^Tx+\theta_0$，其法线方向的向量用数学来表示就是：其法线方法我们用一个列向量$w$来表示,那么就有$\theta^Tw = 0$， 

>如果想要一个已经分好的分隔的超平面保持位置不变，但是要将所有的正标号的点都分类为负数，所有负标号的点都分类为正数，可以怎么修改$\theta$与$\theta_0$？
>
>修改的方式就是将所有的$\theta$和$\theta_0$取为相反数即可；这样以来线性分类器的位置还是不会发生变化，可是$sign(\theta^Tx+\theta_0)$则会取成相反数；



### 4. 学习线性分类器

现在给了一组数据，以及线性分类器(hypothesis class)，我们的目标就是要找到一个线性分类器，这个线性分类器有尽可能小的训练误差；

*这是一个看起来形式很好的一个优化问题，可是求解起来并不那么容易*

我们首先考虑一个非常简单的学习算法，这个算法的基本的想法就是产生k个可能的假设(通过生成一些随机的参数来找到一个假设的超平面，也就是这里的hypothesis;)，这些假设的参数是通过随机来产生的，然后我们在测试集上面评估这k个假设的训练误差，并且返回那么在训练集上的误差最小的那个假设(hypothesis)

>这个方法是能够想到的“最笨”的解决方案了；

RANDOM-LINEAR-CLASSIFIER($D_n$, $k$, $d$)

for j = 1 to k
		randomly sample$(\theta^j, \theta_0^j) $from $(\mathcal{R^d}, \mathcal{R})$
$j^*$ = arg$\min_{j\in{1,...,l}}\epsilon_n(\theta^j, \theta_0^j)$

return  (($\theta^{j^*}$,$\theta_0^{j^{*}}$）

>arg$\min_{j\in{1,...,l}}\epsilon_n(\theta^j, \theta_0^j)$表示的是使得目标函数值最小的一组参数值，当我们想要明确指定我们想要最小化的x值的所在集合是X时，我们会这么来写 $arg min_{x \in X}f(x)$

>随着k的增加，你认为$\epsilon_n(h)$会有什么变化？ 随着k的增加$\epsilon_n(h)$的取值会越来越小；因为命中的范围不断的增加；对于数据集$D_n$，如果数据的维度越高，那么$\epsilon_n(h)$越不容易找到；



### 5. 评价一个学习算法

我们如何来评价一个分类器$h$的效果呢？最好的方法就是在用这里训练器来分类没有见过的测试数据，通过确定测试误差$test\  error$来看看这个分类器到底好不好；

那么我们如何评价一个学习算法的水平如何？这个就有点技巧了，因为在学习假设h上计算测试误差的可能结果中存在许多潜在的可变性来源：

- 到底是在数据集$D_n$中的哪些部分作为训练样本出现的？
- 到底是哪些作为测试样本出现的？
- 这个学习算法本身也存在着一定的随机性；

一般来说，我们想要多次执行下面的操作过程：

- 在新的训练集上面进行训练
- 在测试集上面评估以及学习好了的模型$h$，而用来评估的测试集与训练集是没有重合的；

通过像这样多次进行试验的话，我们就可以控制因为训练过程中数据的选择或者因为算法本身的随机性导致的差的模型出现；

然而使用上面这种实验过程，我们可能会需要大量的数据，但是在许多实际应用的场景中，数据都非常的昂贵并且难以获得，我们可以通过交叉验证$cross\ validation$来对数据进行复用(尽管交叉验证很难用来做理论分析)

>在这里是评估不同的学习算法，而不是评估一个分类器，因为作为分类器如果训练出来了那么它就完成了，但是算法就不同了，算法会包含有许多随机的因素

CROSS-VALIDATE(D, k)

divide $D$ into $k$ chunks, $D_1, D_2, …, D_k$(of roughly equal size)

for i = 1 to k：

​		train $h_i$ on $D \backslash D_i  $(withholding chunk $D_i$)

​		compute “test” error $\epsilon_i(h_i)$ on withheld data $D_i$

return $\frac 1 k \sum_{i=1}^k \epsilon_i{h_i}$

有一点需要强调的是: 交叉验证既不是实现一个特定的particular hypothesis h， 也不是评价一个特定的hypothesis h, 它只是评价产生hypotheses的一个算法的方法；



