### 1 简介

我们会继续拓宽我们的模型来适应更多的数据，神经网络已经足够的复杂了，也就是说，我们可以使用神经网络来尝试出各种各样不同的结构模型，并且通过使用交叉验证来找到在我们的数据上适用得非常好的那个模型；

我们在这一节要研究的模型是能够自动的更加训练集中的数据来调整自己模型的复杂度；无参数方法这个名字听上去有点让人误解；其实上，这一类的方法不需要提前设定固定的参数，一些无参数的模型，比如说决策树，我们可能会称其为“半参数的方法”，这种方法可以被看作是动态的构建某个东西，然后最后看起来更像一个传统的参数模型；但是实际的训练数据终究会影响最后模型的形式。其他的无参数的方法，比如说最近邻算法，就是直接依赖于数据来做预测并且并不会计算一个能够总结数据的模型；

半参数方法倾向于具有简单模型组合的形式，接下来，我们会讨论如下的模型：

- 树模型:通过划分输入空间并在空间的不同区域使用不同的简单预测; 这增加了假设空间。
- 叠加模型:通过在整个空间训练几个不同的分类器并平均答案; 这种方法减少了估计误差。

Boosting是一种构建一个减少估计和结构误差的叠加模型的方法，但我们不会在这课上讨论它。



### 2 树

