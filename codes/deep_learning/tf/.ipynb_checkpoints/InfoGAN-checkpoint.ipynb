{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import platform as _platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "\n",
    "LAST_CKPT = 132000 # Number of last checkpoint to restore and resume training from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating directory for saved models\n",
      "creating directory for saved images\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = \"./models\"\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR): # Create model directory if it does not exist\n",
    "    print(\"creating directory for saved models\")\n",
    "    os.mkdir(MODEL_DIR)\n",
    "if not os.path.isdir(MODEL_DIR + \"/images\"): # Create images directory\n",
    "    print(\"creating directory for saved images\")\n",
    "    os.mkdir(MODEL_DIR + \"/images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 150000 # training epochs | default = 100000\n",
    "batch_size = 64 # batch size | default = 50\n",
    "alpha=0.1 # Leaky RELU alpha | range(0.0,1.0) | default = 0.1\n",
    "lambd=1.0 # lambda for entropy term L(G,Q) | range(0.0,1.0) | default = 1.0\n",
    "z_dim = 100 # Latent space z, for generator | default = 100\n",
    "c_dim = 10 # Latent space c. For MNIST: c=10 (Categorical input with 10 classes)\n",
    "d_alpha = 0.0003 # discriminator learning rate | default = 0.0003\n",
    "g_alpha = 0.0001 # generator learning rate | default = 0.0001\n",
    "q_alpha = 0.0001 # q learning rate | default = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional utility function for Xavier initialization\n",
    "def xavier_init(dim):\n",
    "    d = dim[0]\n",
    "    x_stddev = 1.0 / tf.sqrt(d / 2.0)\n",
    "    return tf.random_normal(shape=dim, stddev=x_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x104e85950>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = mnist.train.next_batch(1)[0]\n",
    "sample = sample.reshape([28, 28])\n",
    "plt.imshow(sample, cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, c_dim, batch_size, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope: \n",
    "        # First convolutional and pool layers\n",
    "        # This finds 32 different 5 x 5 pixel features\n",
    "        d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d1 = d1 + d_b1\n",
    "        d1 = tf.maximum(d1, alpha*d1) # Leaky Relu\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # Second convolutional and pool layers\n",
    "        # This finds 64 different 5 x 5 pixel features\n",
    "        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.maximum(d2, alpha*d2) # Leaky Relu\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # First fully connected layer\n",
    "        d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "        d3 = tf.matmul(d3, d_w3)\n",
    "        d3 = d3 + d_b3\n",
    "        d3 = tf.maximum(d3, alpha*d3) # Leaky Relu\n",
    "\n",
    "        # Second fully connected layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "        \n",
    "        # Calculate Q(c|x) using fully connected layer\n",
    "        q_w1 = tf.get_variable('q_w1', [1, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        q_b1 = tf.get_variable('q_b1', [1024], initializer=tf.constant_initializer(0))\n",
    "        q1 = tf.matmul(d4, q_w1) + q_b1\n",
    "        q1 = tf.maximum(q1, alpha*q1) # Leaky Relu\n",
    "                \n",
    "        # Linear output layer for Q\n",
    "        # No activation, and no softmax here. We will calculate entropy in optimization step (same as discriminator)\n",
    "        q_w2 = tf.get_variable('q_w2', [1024, c_dim], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        q_b2 = tf.get_variable('q_b2', [c_dim], initializer=tf.constant_initializer(0))\n",
    "        Qcx = tf.matmul(q1, q_w2) + q_b2\n",
    "        \n",
    "        # d4 and Qcx contain unscaled values\n",
    "        return d4, Qcx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(c, z, batch_size, c_dim, z_dim, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n",
    "        c = tf.reshape(c, [batch_size, -1]) # reshape: [batch_size, <flattened>] input: [batch_size, c_dim]\n",
    "        z_latent = tf.concat([z,c], axis=1) # include latent layer c with z tensor as input to generator\n",
    "        \n",
    "        g_w1 = tf.get_variable('g_w1', [z_dim + c_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g1 = tf.matmul(z_latent, g_w1) + g_b1\n",
    "        g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "        g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "        g1 = tf.nn.relu(g1)\n",
    "\n",
    "        # Generate 50 features\n",
    "        g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        g2 = g2 + g_b2\n",
    "        g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "        g2 = tf.nn.relu(g2)\n",
    "        g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "        # Generate 25 features\n",
    "        g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        g3 = g3 + g_b3\n",
    "        g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "        g3 = tf.nn.relu(g3)\n",
    "        g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "        # Final convolution with one output channel\n",
    "        g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        g4 = g4 + g_b4\n",
    "        g4 = tf.sigmoid(g4)\n",
    "\n",
    "        # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "        return g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession() #start interactive session for Jupyter notebook\n",
    "\n",
    "z_noise = tf.placeholder(tf.float32, [None, z_dim], name=\"z_placeholder\")\n",
    "c_sim = tf.placeholder(tf.float32, [None, c_dim], name=\"c_placeholder\")\n",
    "\n",
    "g_sample = generator(c_sim, z_noise, 1, c_dim, z_dim)\n",
    "\n",
    "# Noise sampling for generator inputs\n",
    "z_batch = np.random.normal(0, 1, [1, z_dim]) # Start with Gaussian noise\n",
    "c_batch = np.random.multinomial(1, c_dim*[1.0/c_dim], size=1) # Simulated categorical softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGQFJREFUeJzt3XmMFdS9B/Dvj5EBBhBFtmGTRaoghm1cKmB9FawVhBJbK1GD1ohNqdFGzTMk7bO1r5LmVW3MSw0KalsXSC2Klb6HGS2LtcAACsi+DNsMOwjDPvB7f8zlZVDO94wzw73Tnu8nIbN877n3zL3z4869ZzN3h4ikp1GuOyAiuaHiF0mUil8kUSp+kUSp+EUSpeIXSZSKXyRRKn6RRKn4RRJ1QTZvrKCgwFu1ahXMmzVrRtsfOXIkmLVo0YK2rayspHnjxo1pfvjw4WDWtGlT2vb48eM0z8/Pp/nJkydpzmZpxtrGcvZ41cSJEyeCGXs8Af5zAUBeXh7NO3ToEMwOHDhA28Ye02PHjtG8oqKC5k2aNAlmsd9Flu/duxcVFRVGryCjTsVvZrcA+C2APAAvufskdvlWrVrhvvvuC+Z9+vSht7ds2bJgNmTIENp27969NGe/KADwj3/8I5hdccUVtO369etp3q1bN5pv376d5qzAduzYQduWl5fTfNSoUTSP/ae6ZcuWYMYeTyBeYBdffDHNH3/88WA2c+ZM2rZ37940X7NmDc3nz59P8x49egSz2O9iYWFhMHv66adp2+pq/We/meUB+G8A3wbQB8BYM+PVKyINRl1e818DYL27b3T3EwDeBDC6frolIudbXYq/E4Ct1b7elvneWcxsvJmVmFlJ7DWeiGRPXYr/XG8qfOkdGnef7O5F7l5UUFBQh5sTkfpUl+LfBqBLta87AyirW3dEJFvqUvyLAPQys+5mlg/gTgD8LVQRaTBqPdTn7pVm9mMA/4uqob6p7v4Za3P8+HFs2LCBXSe9zfvvvz+Yvf7667Ttxo0baX7ZZZfR/Oqrrw5mzz//PG07bNgwmm/dupXmJSUlNO/bt28wY0OrAPDuu+/SPDYcd9ddd9H8r3/9azBbvXo1bTt27Fiat2nThuYff/xxMGvdujVtGxvCbNSIP28WFRXRfNCgQcHsgw8+oG3ZOH+s39XVaZzf3WcBmFWX6xCR3ND0XpFEqfhFEqXiF0mUil8kUSp+kUSp+EUSldX1/M2aNcNVV10VzGPrmOfOnRvMiouLadsRI0ZE+8YcPHgwmA0dOpS2PXXqFM3ZWDjA5xgAfEnwggULaNvTp0/TvGvXrjSfOHEizUeOHBnMBg8eTNsuXLiQ5pMm0RXkeO2114JZbJ+C2F4BsbkZsWXa7GeLLSdmezDE5h+cddkaX1JE/qWo+EUSpeIXSZSKXyRRKn6RRKn4RRKV1aG+vLw8tGzZMpiXlfG9QNhOtNdff32t+wUAR48erfVts2XKQHzp6c9+9jOaz5gxg+Zs6GfWLL7osmfPnjRnQ3VAfCk02+U2tt167LYnT55Mc3a/xIY4165dS/OPPvqI5p06fWlHu7NcdNFFwSw2jMh2/tVQn4hEqfhFEqXiF0mUil8kUSp+kUSp+EUSpeIXSVRWx/lPnTpFj7qOHVXNTmXt3LkzbRsbl42d+MrGT2NbjseWj8ZOdL311ltp/oc//CGYxZbksm2/AeCzz+hu7Ni0aRPNBwwYEMyWL19O28aWxca232bLtGPLx2PzPkaP5sdSxrbQZvdb7Ej3e+65J5jF5k5Up2d+kUSp+EUSpeIXSZSKXyRRKn6RRKn4RRKl4hdJVJ3G+c2sFMAhAKcAVLo7PZfYzOj4amFhIb09NjYaO4K7T58+NI/NMWjevHkwi22tHVtTH9uLYOnSpTTfv39/MJswYQJtGzsOmq0dB+Lr4ufNmxfMjhw5QtuWlpbS/KGHHqL5zJkzgxl7PIH4HAI2XwXgW70D/PcxtpfA+vXrg1lsjkB19THJ59/cfU89XI+IZJH+7BdJVF2L3wHMNrPFZja+PjokItlR1z/7B7t7mZm1A/C+ma1297PO1Mr8pzAe4PuWiUh21emZ393LMh93AZgB4JpzXGayuxe5e1HsTRYRyZ5aF7+ZNTezlmc+B3AzgBX11TEROb/q8md/ewAzzOzM9bzu7v9TL70SkfOu1sXv7hsB9PsqbfLz89GlS5dgXlJSQttfeOGFwSy2frpJkyY0j70fsXLlymDGfiYAKCgooPmyZctoHtv3n41JT5kyhbYdNGgQzffs4aO4saOs2X4C06ZNo23btm1L87feeovmbB7BBRfwX/19+/bRPLZu/sCBAzRnexV07NiRtt2+fXswO3HiBG1bnYb6RBKl4hdJlIpfJFEqfpFEqfhFEqXiF0lU1rfu/vzzz4N5URFdEUyXtl5yySW0bWx56LFjx2jOhlfat29P28a2qB43bhzNi4uLac6GAu+44446XXdsi+vYz87u99j9csstt9A89pixZdq9evWibdnR4kB8OXK/fnwUnB1tHjtmmw2/xoa8z7qdGl9SRP6lqPhFEqXiF0mUil8kUSp+kUSp+EUSpeIXSVRWx/nNjI5hLliwoNbXzY5jBuLHYLP5BwDf6nnhwoW07QMPPEDz2DbQ3/jGN2i+YkV4D5XY1tyxI7avvPJKmm/bto3mbEv1p556iraNLW1dtGgRzdnvWuzo8dWrV9O8Z8+eNH/nnXdoPmbMmGAWmzvB5jfEllhXp2d+kUSp+EUSpeIXSZSKXyRRKn6RRKn4RRKl4hdJVFbH+WNbd8e0bNkymB09epS2LS8vp3lsLwE29hqbIxCbvzB8+HCax7aBZttIuztte+mll9I8dlR1p06daM76zravBoBVq1bRPGbLli3B7Pbbb6dt27VrR/MlS5bQPPb7xOZ2sL0jgK82ls/omV8kUSp+kUSp+EUSpeIXSZSKXyRRKn6RRKn4RRIVHec3s6kARgLY5e59M99rDWAagG4ASgHc4e77Y9d16NAhzJkzJ5jH9kpnY+2xfftj6/lj490//OEPg5mZ0banTp2iOVuPDwB/+ctfaM7GpIcMGULbxuZHbN68meYDBw6kOdtnIfaYNG3alOatWrWiOds7f9KkSbTtr3/9a5qXlZXRvEOHDjQ/ePBgMIvtTcGOD4/9rlVXk2f+VwB88fSEJwAUu3svAMWZr0Xkn0i0+N19LoAv/lczGsCrmc9fBfCdeu6XiJxntX3N397dywEg85HPhRSRBue8v+FnZuPNrMTMSmLnm4lI9tS2+HeaWSEAZD7uCl3Q3Se7e5G7FxUUFNTy5kSkvtW2+GcCOHO07DgAfKtSEWlwosVvZm8A+BjA5Wa2zczuBzAJwHAzWwdgeOZrEfknEh3nd/exgeimr3pjJ0+exI4dO4L5rl3BVw8AgKuvvjqYxeYIvPLKK3XK33vvvWB20UUX0bZ33303zWNrv19++WWas7H42Jr42BwFtocCAGzdupXm7HH5/ve/T9uysXAgvkcDW3MfO0uhtLSU5rHzCq644gqav/TSS8HsV7/6FW27fv36YFZZWUnbVqcZfiKJUvGLJErFL5IoFb9IolT8IolS8YskymJbO9en9u3b+1133RXMY8cmr127NpjFhtNiS1djQ1psaezf/vY32nb27Nk0Hzp0KM2feIIvmnzooYeCWeyI7dhw2okTJ2i+dOlSmj/44IPBrKSkhLZlR2wD8cesoqIimPXo0YO2bdy4Mc1PnjxJ89hjzo5djw1hsq27X375ZZSXl/Px2ww984skSsUvkigVv0iiVPwiiVLxiyRKxS+SKBW/SKKyekR3Xl4e3W45dizyrbfeGsxi2zzHlguzI5MB4I9//GMwy8/Pp21jR3Q//PDDNP/5z39OczZmfPz4cdo2tsU0Wz4KAD/96U9p/swzzwSzr3/967TtVVddRXO2zBqIb+fOxLbAvvbaa2m+cOHCWuexn5sdbR7b9rs6PfOLJErFL5IoFb9IolT8IolS8YskSsUvkigVv0iisjrOn5+fj65duwbz2HbHv/zlL4PZ2LGhHcarnD59muaXXXYZzZs0aRLMPvroI9r2zTffpHlsH4Mf/OAHNF+0aFEwi411L168mObXX389zWfNmkVzdkRbbH7EypUraT5q1CiaFxcXB7PWrVvTtu+//z7NZ8yYQfObbuI727PHJTY3Y8OGDbVuW52e+UUSpeIXSZSKXyRRKn6RRKn4RRKl4hdJlIpfJFHRcX4zmwpgJIBd7t43870nATwAYHfmYhPdnQ/4omoP+C1btgTz2F7qbM//2P7006ZNo/mePXtozvZxv/3222nb2HHPXbp0oXlsbTnLY3MnOnbsSHO2RzwArFu3juYDBw4MZjt37qRtmzdvTvO9e/fSnB2dHvu5Y4/p3Llzab5//36aszMJLr74YtqWnVcQe7zO6kMNLvMKgFvO8f1n3b1/5l+08EWkYYkWv7vPBbAvC30RkSyqy2v+H5vZMjObamb87xQRaXBqW/y/A9ATQH8A5QB+E7qgmY03sxIzK2HzvEUku2pV/O6+091PuftpAC8CuIZcdrK7F7l7UUFBQW37KSL1rFbFb2aF1b4cA2BF/XRHRLKlJkN9bwC4EUAbM9sG4D8A3Ghm/QE4gFIA4XOYRaRBiha/u59rofyU2txYkyZN6J7jsXHftWvXBrPNmzfTtt27d6c522cA4PsBuDttu3HjRpr36dOH5i+88ALNhw4dGsymT59O244ZM4bmsfkPLVq0oDmbH3Ho0CHaNvaYxc5iYGP5Tz/9NG375JNP0rysrIzmsXknu3fvDmarVq2ibYcNGxbMLrig5lt0aIafSKJU/CKJUvGLJErFL5IoFb9IolT8IonK6tbdJ0+epEMkbPgDAO69995gFltiGRtWYkeHA/yo6tiQVGw4bOnSpTS/7bbbaG5mweyGG26gbWOzLufNm0fz2BbYbBi0Z8+etG1FRQXNY0tf2dBxbKlz7OeOHaPdtm1bmu/YsSOYseW+AF8uHFv+fdbt1PiSIvIvRcUvkigVv0iiVPwiiVLxiyRKxS+SKBW/SKKyOs7fqFEjOq4cOyb7008/DWZbt26lbWPbY3/wwQc0Z2Orn3/+OW0b61tsWW15eTnNH3vssWDWr18/2vYXv/gFzWNbc1933XU0Z2P5sa232fwFAJg5cybN+/fvH8zYkes1yTt16kTz7du30/y73/1uMIttM8+WScfus+r0zC+SKBW/SKJU/CKJUvGLJErFL5IoFb9IolT8Iomy2LbT9alDhw5+9913B3N2pDLAt8AeMmQIbRvbDjk2PsrW5LOtswHgjTfeoHnsGLMRI0bQPD8/P5jNmDGDth0+fDjNmzZtSvM5c+bQnG0z/eKLL9K2sfkPBw4coDk7Dj52n9988800X7lyJc23bdtGc7a195o1a2jb48ePB7P33nsPe/bsqdFgv575RRKl4hdJlIpfJFEqfpFEqfhFEqXiF0mUil8kUdH1/GbWBcDvAXQAcBrAZHf/rZm1BjANQDcApQDucPfwondUjU+WlpYG83HjxtG+sDkJsbXd3/rWt2h++PBhmn/22WfBLLa2O3bM9ahRo2gem4vB5jDE7tPY/Ie3336b5oMHD6Y524PhzjvvpG1jZwrE9klgczdi++4/++yzNI/93L1796b50aNHg1lsvsumTZuCGTtK/otq8sxfCeBRd+8N4DoAE8ysD4AnABS7ey8AxZmvReSfRLT43b3c3ZdkPj8EYBWATgBGA3g1c7FXAXznfHVSROrfV3rNb2bdAAwAsABAe3cvB6r+gwDQrr47JyLnT42L38xaAHgLwCPufvArtBtvZiVmVsLmJItIdtWo+M2sMaoK/zV3/3Pm2zvNrDCTFwLYda627j7Z3YvcvSi2KaKIZE+0+K3qLdMpAFa5+zPVopkAzryVPA7AO/XfPRE5X6JLes1sCIB5AJajaqgPACai6nX/dABdAWwB8D1338euq1WrVs6GSGLDcY888kgwe/TRR2nbkydP0jzmwgsvDGZ5eXl1uu7Yy6HY8eLNmzcPZrEjtGPDSrGlq7GfnT3eixYtom0LCwtpPn/+fJp369YtmLVrx9+iYkNxQPx48Nj1f/jhh8GMDeXFbnv27NnYt29fjZb0Rsf53X0+gNCV3VSTGxGRhkcz/EQSpeIXSZSKXyRRKn6RRKn4RRKl4hdJVFaP6G7WrBn69OkTzGNHXT/11FPBLDZeHRu3/fjjj2neo0ePYBYb041t43zJJZfQvGXLljRn476x+Q2xeR6XXnopzWNzEF544YVgFtseO3a/xu6Xvn37BrPY/IXY/daxY0eaHzt2jObsd33QoEG0LVvqPG/ePNq2Oj3ziyRKxS+SKBW/SKJU/CKJUvGLJErFL5IoFb9IorI6zn/69Gk6/tm4cWPanm3FHBsT3rx5M81Hjx5NczbePWXKFNp2wIABNGdzCABg8eLFNK+oqAhm1157LW1bWVlJ8w0bNtA8NtY+cuTIYFZWVkbbsqPHgfjPtmDBgmDG9kAAgMsvv5zms2bNovl9991H84EDBwaz/fvpDvjo3LlzMIvdZ9XpmV8kUSp+kUSp+EUSpeIXSZSKXyRRKn6RRKn4RRKV1XH+Dh064PHHHw/mU6dOpe179epV67YTJkygeWyewOrVq4NZ7IjuZcuW0fzee++l+d///neas/X8sePBi4uLaR5bW37kyJFa52y9PQCcOHGC5gcP8lPj2rdvH8xieyi88w4/g+bKK6+k+YoVK2jOzhSIzUlp06ZNMLvggpqXtJ75RRKl4hdJlIpfJFEqfpFEqfhFEqXiF0mUil8kUdFBQTPrAuD3ADoAOA1gsrv/1syeBPAAgN2Zi050d7rI+cCBA3j33XeD+eHDh2lffvSjHwWz559/nradPXs2zW+6iZ82vnTp0mDWs2dP2rZ169Y0f+yxx2g+bNgwmq9ZsyaYffLJJ7Rt27ZtaR5brx/bt//UqVPBLHZOQ+wshtiafDYv5E9/+hNt+5Of/ITmsfax+5WdG9CiRQvalp1Bcfr0adq2uprMCKgE8Ki7LzGzlgAWm9n7mexZd/+vGt+aiDQY0eJ393IA5ZnPD5nZKgB8SpuINHhf6TW/mXUDMADAmf2Rfmxmy8xsqpmdc46pmY03sxIzK2HbTYlIdtW4+M2sBYC3ADzi7gcB/A5ATwD9UfWXwW/O1c7dJ7t7kbsXxV7LiEj21Kj4zawxqgr/NXf/MwC4+053P+XupwG8COCa89dNEalv0eK3qi1zpwBY5e7PVPt+YbWLjQHAlzGJSINSk3f7BwO4B8ByMzszbjQRwFgz6w/AAZQCeDB2RZWVldi7d28w79+/P20/ffr0YMa2aQbiQyCxoRk27LR79+5gBsSXaBYWFtJ8+fLlNP/a174WzGLDjKWlpTTftWsXzWPbjrOl0LFjsmO/D7ElvWwLbLakFohvl967d2+aDxkyhOaffvppMJs2bRpt26xZs2AWO4q+upq82z8fwLk2zOcbl4tIg6YZfiKJUvGLJErFL5IoFb9IolT8IolS8YskKqtbdzdp0oSOr8a2U96xY0cw69evH20bG9fNy8ujOZsn8M1vfpO23bRpE81jxyrHxm7Z1t2x5cZNmzaleex+Y0t2Ad732Dh+q1ataN69e3eaL1myJJjddttttO26detoHlvKPGfOHJo/99xzwWzEiBG0bUFBQTBr1Kjmz+d65hdJlIpfJFEqfpFEqfhFEqXiF0mUil8kUSp+kUSZu2fvxsx2A6i+uL0NAH6GdO401L411H4B6ltt1WffLnV3vjlFRlaL/0s3blbi7kU56wDRUPvWUPsFqG+1lau+6c9+kUSp+EUSlevin5zj22caat8aar8A9a22ctK3nL7mF5HcyfUzv4jkSE6K38xuMbM1ZrbezJ7IRR9CzKzUzJab2SdmVpLjvkw1s11mtqLa91qb2ftmti7zMbyeN/t9e9LMtmfuu0/M7NYc9a2LmX1oZqvM7DMzezjz/Zzed6RfObnfsv5nv5nlAVgLYDiAbQAWARjr7nwT9ywxs1IARe6e8zFhM7sBQAWA37t738z3fg1gn7tPyvzHebG7/3sD6duTACpyfXJz5kCZwuonSwP4DoB7kcP7jvTrDuTgfsvFM/81ANa7+0Z3PwHgTQCjc9CPBs/d5wLY94VvjwbwaubzV1H1y5N1gb41CO5e7u5LMp8fAnDmZOmc3nekXzmRi+LvBGBrta+3oWEd+e0AZpvZYjMbn+vOnEP7zLHpZ45Pb5fj/nxR9OTmbPrCydIN5r6rzYnX9S0XxX+u038a0pDDYHcfCODbACZk/ryVmqnRyc3Zco6TpRuE2p54Xd9yUfzbAHSp9nVnAGU56Mc5uXtZ5uMuADPQ8E4f3nnmkNTMR36YXhY1pJObz3WyNBrAfdeQTrzORfEvAtDLzLqbWT6AOwHMzEE/vsTMmmfeiIGZNQdwMxre6cMzAYzLfD4OwDs57MtZGsrJzaGTpZHj+66hnXidk0k+maGM5wDkAZjq7v+Z9U6cg5n1QNWzPVC1s/Hrueybmb0B4EZUrfraCeA/ALwNYDqArgC2APieu2f9jbdA325E1Z+u/39y85nX2Fnu2xAA8wAsB3Bm2+WJqHp9nbP7jvRrLHJwv2mGn0iiNMNPJFEqfpFEqfhFEqXiF0mUil8kUSp+kUSp+EUSpeIXSdT/AZZyHgswSV2FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "image = sess.run(g_sample, feed_dict={z_noise: z_batch,c_sim: c_batch})\n",
    "image = image.reshape([28, 28])\n",
    "plt.imshow(image, cmap='gist_gray')\n",
    "sess.close() # End interactive session for Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input noise to the generator\n",
    "z_noise = tf.placeholder(tf.float32, [None, z_dim], name='z_noise') \n",
    "# simulated input noise for latent variable c\n",
    "c_sim = tf.placeholder(tf.float32, [None, c_dim], name=\"c_sim\")\n",
    "# input images to discriminator\n",
    "x_in = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_in') \n",
    "# Generator\n",
    "Gz = generator(c_sim, z_noise, batch_size, c_dim, z_dim) \n",
    "# Discriminator Real (prediction probabilities for the real images)\n",
    "Dx, _ = discriminator(x_in, c_dim, batch_size) \n",
    "# Discriminator Fake (prediction probabilities for the generated images) and Q latent predictions\n",
    "Dg, Qcx = discriminator(Gz, c_dim, batch_size, reuse_variables=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InfoGANLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy of Q: lambda*L(G,Q)\n",
    "q_H = tf.reduce_mean(lambd*tf.nn.sigmoid_cross_entropy_with_logits(logits = tf.nn.softmax(Qcx), labels = c_sim))\n",
    "\n",
    "# infoGAN loss function: Loss = V(D,G) - lambda*L(G,Q)\n",
    "q_loss = tf.abs((g_loss - q_H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'd_w1:0', u'd_b1:0', u'd_w2:0', u'd_b2:0', u'd_w3:0', u'd_b3:0', u'd_w4:0', u'd_b4:0']\n",
      "[u'g_w1:0', u'g_b1:0', u'g_w2:0', u'g_b2:0', u'g_w3:0', u'g_b3:0', u'g_w4:0', u'g_b4:0']\n",
      "[u'q_w1:0', u'q_b1:0', u'q_w2:0', u'q_b2:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "q_vars = [var for var in tvars if 'q_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])\n",
    "print([v.name for v in q_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the discriminator\n",
    "d_train_fake = tf.train.AdamOptimizer(d_alpha).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_train_real = tf.train.AdamOptimizer(d_alpha).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_train = tf.train.AdamOptimizer(g_alpha).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "# Train the latent variables, update q and g parameters\n",
    "q_train = tf.train.AdamOptimizer(q_alpha).minimize(q_loss, var_list=q_vars+g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this point forward, reuse variables\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "tf.summary.scalar('Q_loss', q_loss)\n",
    "tf.summary.scalar('Q_entropy', q_H)\n",
    "\n",
    "images_for_tensorboard = generator(c_sim, z_noise, batch_size, c_dim, z_dim)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
