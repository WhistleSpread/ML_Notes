{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import platform as _platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "\n",
    "LAST_CKPT = 132000 # Number of last checkpoint to restore and resume training from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./models\"\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR): # Create model directory if it does not exist\n",
    "    print(\"creating directory for saved models\")\n",
    "    os.mkdir(MODEL_DIR)\n",
    "if not os.path.isdir(MODEL_DIR + \"/images\"): # Create images directory\n",
    "    print(\"creating directory for saved images\")\n",
    "    os.mkdir(MODEL_DIR + \"/images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 150000 # training epochs | default = 100000\n",
    "batch_size = 64 # batch size | default = 50\n",
    "alpha=0.1 # Leaky RELU alpha | range(0.0,1.0) | default = 0.1\n",
    "lambd=1.0 # lambda for entropy term L(G,Q) | range(0.0,1.0) | default = 1.0\n",
    "z_dim = 100 # Latent space z, for generator | default = 100\n",
    "c_dim = 10 # Latent space c. For MNIST: c=10 (Categorical input with 10 classes)\n",
    "d_alpha = 0.0003 # discriminator learning rate | default = 0.0003\n",
    "g_alpha = 0.0001 # generator learning rate | default = 0.0001\n",
    "q_alpha = 0.0001 # q learning rate | default = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional utility function for Xavier initialization\n",
    "def xavier_init(dim):\n",
    "    d = dim[0]\n",
    "    x_stddev = 1.0 / tf.sqrt(d / 2.0)\n",
    "    return tf.random_normal(shape=dim, stddev=x_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2a1a9c90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = mnist.train.next_batch(1)[0]\n",
    "sample = sample.reshape([28, 28])\n",
    "plt.imshow(sample, cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, c_dim, batch_size, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope: \n",
    "        # First convolutional and pool layers\n",
    "        # This finds 32 different 5 x 5 pixel features\n",
    "        d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d1 = d1 + d_b1\n",
    "        d1 = tf.maximum(d1, alpha*d1) # Leaky Relu\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # Second convolutional and pool layers\n",
    "        # This finds 64 different 5 x 5 pixel features\n",
    "        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.maximum(d2, alpha*d2) # Leaky Relu\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # First fully connected layer\n",
    "        d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "        d3 = tf.matmul(d3, d_w3)\n",
    "        d3 = d3 + d_b3\n",
    "        d3 = tf.maximum(d3, alpha*d3) # Leaky Relu\n",
    "\n",
    "        # Second fully connected layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "        \n",
    "        # Calculate Q(c|x) using fully connected layer\n",
    "        q_w1 = tf.get_variable('q_w1', [1, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        q_b1 = tf.get_variable('q_b1', [1024], initializer=tf.constant_initializer(0))\n",
    "        q1 = tf.matmul(d4, q_w1) + q_b1\n",
    "        q1 = tf.maximum(q1, alpha*q1) # Leaky Relu\n",
    "                \n",
    "        # Linear output layer for Q\n",
    "        # No activation, and no softmax here. We will calculate entropy in optimization step (same as discriminator)\n",
    "        q_w2 = tf.get_variable('q_w2', [1024, c_dim], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        q_b2 = tf.get_variable('q_b2', [c_dim], initializer=tf.constant_initializer(0))\n",
    "        Qcx = tf.matmul(q1, q_w2) + q_b2\n",
    "        \n",
    "        # d4 and Qcx contain unscaled values\n",
    "        return d4, Qcx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(c, z, batch_size, c_dim, z_dim, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n",
    "        c = tf.reshape(c, [batch_size, -1]) # reshape: [batch_size, <flattened>] input: [batch_size, c_dim]\n",
    "        z_latent = tf.concat([z,c], axis=1) # include latent layer c with z tensor as input to generator\n",
    "        \n",
    "        g_w1 = tf.get_variable('g_w1', [z_dim + c_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g1 = tf.matmul(z_latent, g_w1) + g_b1\n",
    "        g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "        g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "        g1 = tf.nn.relu(g1)\n",
    "\n",
    "        # Generate 50 features\n",
    "        g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        g2 = g2 + g_b2\n",
    "        g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "        g2 = tf.nn.relu(g2)\n",
    "        g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "        # Generate 25 features\n",
    "        g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        g3 = g3 + g_b3\n",
    "        g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "        g3 = tf.nn.relu(g3)\n",
    "        g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "        # Final convolution with one output channel\n",
    "        g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        g4 = g4 + g_b4\n",
    "        g4 = tf.sigmoid(g4)\n",
    "\n",
    "        # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "        return g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession() #start interactive session for Jupyter notebook\n",
    "\n",
    "z_noise = tf.placeholder(tf.float32, [None, z_dim], name=\"z_placeholder\")\n",
    "c_sim = tf.placeholder(tf.float32, [None, c_dim], name=\"c_placeholder\")\n",
    "\n",
    "g_sample = generator(c_sim, z_noise, 1, c_dim, z_dim)\n",
    "\n",
    "# Noise sampling for generator inputs\n",
    "z_batch = np.random.normal(0, 1, [1, z_dim]) # Start with Gaussian noise\n",
    "c_batch = np.random.multinomial(1, c_dim*[1.0/c_dim], size=1) # Simulated categorical softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "image = sess.run(g_sample, feed_dict={z_noise: z_batch,c_sim: c_batch})\n",
    "image = image.reshape([28, 28])\n",
    "plt.imshow(image, cmap='gist_gray')\n",
    "sess.close() # End interactive session for Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input noise to the generator\n",
    "z_noise = tf.placeholder(tf.float32, [None, z_dim], name='z_noise') \n",
    "# simulated input noise for latent variable c\n",
    "c_sim = tf.placeholder(tf.float32, [None, c_dim], name=\"c_sim\")\n",
    "# input images to discriminator\n",
    "x_in = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_in') \n",
    "# Generator\n",
    "Gz = generator(c_sim, z_noise, batch_size, c_dim, z_dim) \n",
    "# Discriminator Real (prediction probabilities for the real images)\n",
    "Dx, _ = discriminator(x_in, c_dim, batch_size) \n",
    "# Discriminator Fake (prediction probabilities for the generated images) and Q latent predictions\n",
    "Dg, Qcx = discriminator(Gz, c_dim, batch_size, reuse_variables=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InfoGANLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy of Q: lambda*L(G,Q)\n",
    "q_H = tf.reduce_mean(lambd*tf.nn.sigmoid_cross_entropy_with_logits(logits = tf.nn.softmax(Qcx), labels = c_sim))\n",
    "\n",
    "# infoGAN loss function: Loss = V(D,G) - lambda*L(G,Q)\n",
    "q_loss = tf.abs((g_loss - q_H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'd_w1:0', u'd_b1:0', u'd_w2:0', u'd_b2:0', u'd_w3:0', u'd_b3:0', u'd_w4:0', u'd_b4:0']\n",
      "[u'g_w1:0', u'g_b1:0', u'g_w2:0', u'g_b2:0', u'g_w3:0', u'g_b3:0', u'g_w4:0', u'g_b4:0']\n",
      "[u'q_w1:0', u'q_b1:0', u'q_w2:0', u'q_b2:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "q_vars = [var for var in tvars if 'q_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])\n",
    "print([v.name for v in q_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the discriminator\n",
    "d_train_fake = tf.train.AdamOptimizer(d_alpha).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_train_real = tf.train.AdamOptimizer(d_alpha).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_train = tf.train.AdamOptimizer(g_alpha).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "# Train the latent variables, update q and g parameters\n",
    "q_train = tf.train.AdamOptimizer(q_alpha).minimize(q_loss, var_list=q_vars+g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this point forward, reuse variables\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "tf.summary.scalar('Q_loss', q_loss)\n",
    "tf.summary.scalar('Q_entropy', q_H)\n",
    "\n",
    "images_for_tensorboard = generator(c_sim, z_noise, batch_size, c_dim, z_dim)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/infogan.ckpt-132000\n",
      "Model restore unsuccessful. Training from Epoch 0\n",
      "('dLossReal:', 0.6923046, 'dLossFake:', 0.7072575, 'G_Loss:', 0.6792332, 'Q_loss:', 0.055163383, 'Q_entropy:', 0.7343966)\n",
      "('dLossReal:', 2.2521657e-05, 'dLossFake:', 2.9389827e-05, 'G_Loss:', 10.435474, 'Q_loss:', 9.700964, 'Q_entropy:', 0.7345107)\n",
      "('dLossReal:', 1.279212e-05, 'dLossFake:', 2.14542e-05, 'G_Loss:', 10.750412, 'Q_loss:', 10.0158825, 'Q_entropy:', 0.73452914)\n",
      "('Iteration:', 0, 'at', datetime.datetime(2019, 7, 8, 21, 2, 28, 931559))\n",
      "('dLossReal:', 9.069939e-06, 'dLossFake:', 1.6516056e-05, 'G_Loss:', 11.012004, 'Q_loss:', 10.277551, 'Q_entropy:', 0.7344528)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Estimate:', array([[-11.022433]], dtype=float32))\n",
      "('Iteration:', 100, 'at', datetime.datetime(2019, 7, 8, 21, 4, 47, 998977))\n",
      "('dLossReal:', 1.6098018e-05, 'dLossFake:', 3.918879e-05, 'G_Loss:', 10.206632, 'Q_loss:', 9.472266, 'Q_entropy:', 0.7343658)\n",
      "('Iteration:', 200, 'at', datetime.datetime(2019, 7, 8, 21, 7, 6, 361816))\n",
      "('dLossReal:', 2.113188e-05, 'dLossFake:', 3.7437312e-05, 'G_Loss:', 10.249035, 'Q_loss:', 9.514774, 'Q_entropy:', 0.7342601)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6d79cc68f82e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mz_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mc_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_label_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz_noise\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_sim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "try:\n",
    "    MODEL_PATH = MODEL_DIR + '/infogan.ckpt-'\n",
    "    saver.restore(sess, MODEL_PATH + str(LAST_CKPT))\n",
    "    start = LAST_CKPT\n",
    "    print(\"Model restored successfully\")\n",
    "except Exception as e:\n",
    "    start = 0\n",
    "    print(\"Model restore unsuccessful. Training from Epoch 0\")\n",
    "    \n",
    "    # Pre-train discriminator\n",
    "    for i in range(300):\n",
    "        z_batch = np.random.normal(0, 1, [batch_size, z_dim])\n",
    "        c_batch = np.random.multinomial(1, 10*[0.1], size=batch_size)\n",
    "        real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "        _, __, dLossReal, dLossFake, gLoss, qLoss, qH = sess.run([d_train_real, d_train_fake, d_loss_real, d_loss_fake, g_loss, q_loss, q_H],\n",
    "                                               {x_in: real_image_batch, \n",
    "                                                z_noise: z_batch, \n",
    "                                                c_sim: c_batch})\n",
    "\n",
    "        if(i % 100 == 0):\n",
    "            print(\"dLossReal:\", dLossReal, \n",
    "                  \"dLossFake:\", dLossFake, \n",
    "                  \"G_Loss:\", gLoss, \n",
    "                  \"Q_loss:\", qLoss, \n",
    "                  \"Q_entropy:\", qH)\n",
    "\n",
    "# Train generator and discriminator together\n",
    "for i in range(start, nb_epochs):\n",
    "    train_batch = mnist.train.next_batch(batch_size)\n",
    "    real_image_batch = train_batch[0].reshape([batch_size, 28, 28, 1])\n",
    "    real_label_batch = np.eye(c_dim, dtype=np.int)[train_batch[1]]\n",
    "    \n",
    "    z_batch = np.random.normal(0, 1, [batch_size, z_dim])\n",
    "    c_batch = real_label_batch\n",
    "    \n",
    "\n",
    "    # Train discriminator on both real and fake images\n",
    "    _, __, dLossReal, dLossFake, gLoss, qLoss, qH = sess.run([d_train_real, d_train_fake, d_loss_real, d_loss_fake, g_loss, q_loss, q_H],\n",
    "                                           {x_in: real_image_batch, \n",
    "                                            z_noise: z_batch, \n",
    "                                            c_sim: c_batch})\n",
    "\n",
    "    # Train generator\n",
    "    z_batch = np.random.normal(0, 1, [batch_size, z_dim])\n",
    "    c_batch = real_label_batch\n",
    "    _ = sess.run(g_train, feed_dict={z_noise: z_batch, c_sim: c_batch})\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        # Update TensorBoard with summary statistics\n",
    "        z_batch = np.random.normal(0, 1, [batch_size, z_dim])\n",
    "        c_batch = real_label_batch\n",
    "        summary = sess.run(merged, {z_noise: z_batch, c_sim: c_batch, x_in: real_image_batch})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # Every 100 iterations, save a generated image\n",
    "        print(\"Iteration:\", i, \"at\", datetime.datetime.now())\n",
    "        print(\"dLossReal:\", dLossReal, \"dLossFake:\", dLossFake, \"G_Loss:\", gLoss, \"Q_loss:\", qLoss, \"Q_entropy:\", qH)\n",
    "        z_batch = np.random.normal(0, 1, [1, z_dim])\n",
    "        c_batch = np.random.multinomial(1, 10*[0.1], size=1)\n",
    "        generated_images = generator(c_sim, z_noise, 1, c_dim, z_dim)\n",
    "        images = sess.run(generated_images, {z_noise: z_batch, c_sim: c_batch})\n",
    "        plt.imshow(images[0].reshape([28, 28]), cmap='gist_gray')\n",
    "        plt.savefig(MODEL_DIR + \"/images/image-epoch-\" + str(i) + \".png\")\n",
    "        \n",
    "    if i % 1000 == 0:\n",
    "        # Every 1000 iterations, show a generated image\n",
    "        plt.show()\n",
    "\n",
    "        # Show discriminator's estimate\n",
    "        im = images[0].reshape([1, 28, 28, 1])\n",
    "        result, _ = discriminator(x_in, c_dim, 1) \n",
    "        estimate = sess.run(result, {x_in: im, c_sim: c_batch})\n",
    "        print(\"Estimate:\", estimate)\n",
    "    \n",
    "    if (i % 500 == 0) and (i > 0):\n",
    "        # Save Checkpoint\n",
    "        # Use absolute path outside of cloud drive (e.g. Dropbox) to avoid errors\n",
    "        try:\n",
    "            save_path = saver.save(sess, MODEL_DIR + '/infogan.ckpt', global_step=i)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "        except Exception as e:\n",
    "            print(\"Model save failed: {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Restoring and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_CKPT = 100000 # Number of last checkpoint to restore and resume training from\n",
    "saver = tf.train.Saver()\n",
    "images_num = 10 # how many images to show\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, MODEL_DIR + '/infogan.ckpt-' + str(LAST_CKPT))\n",
    "    z_batch = np.random.normal(0, 1, size=[images_num, z_dim])\n",
    "    c_batch = np.random.multinomial(1, 10*[0.1], size=images_num) # random digits\n",
    "    #c_batch = np.identity(images_num) # One example of each digit\n",
    "    z_noise = tf.placeholder(tf.float32, [None, z_dim], name='z_placeholder') \n",
    "    generated_images = generator(c_sim, z_noise, images_num, c_dim, z_dim)\n",
    "    images = sess.run(generated_images, {z_noise: z_batch, c_sim: c_batch})\n",
    "    for i in range(10):\n",
    "        plt.imshow(images[i].reshape([28, 28]), cmap='gist_gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
